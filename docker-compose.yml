version: "3.9"

services:
  # =============================================================================
  # Main FastAPI Orchestration Service
  # =============================================================================
  app:
    build: ./services/app
    container_name: voicebot-app
    env_file: .env
    ports:
      - "8080:8080"
    depends_on:
      - llm
      - stt
      - tts
      - rag
    volumes:
      - ./services/app:/app
    environment:
      - PYTHONUNBUFFERED=1
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/healthz"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  # =============================================================================
  # LLM Service (vLLM or llama.cpp)
  # =============================================================================
  llm:
    build: ./services/llm
    container_name: voicebot-llm
    environment:
      - MODEL_NAME=${MODEL_NAME:-llama-3.1-8b-instruct}
      - CUDA_VISIBLE_DEVICES=${CUDA_VISIBLE_DEVICES:-0}
    ports:
      - "8001:8001"
    volumes:
      - llm_models:/models
    restart: unless-stopped
    # Uncomment for GPU support
    # deploy:
    #   resources:
    #     reservations:
    #       devices:
    #         - driver: nvidia
    #           count: 1
    #           capabilities: [gpu]

  # =============================================================================
  # Speech-to-Text Service (Whisper)
  # =============================================================================
  stt:
    build: ./services/stt
    container_name: voicebot-stt
    environment:
      - WHISPER_MODEL=${WHISPER_MODEL:-base}
      - CUDA_VISIBLE_DEVICES=${CUDA_VISIBLE_DEVICES:-0}
    ports:
      - "8002:8002"
    volumes:
      - stt_models:/models
    restart: unless-stopped
    # Uncomment for GPU support
    # deploy:
    #   resources:
    #     reservations:
    #       devices:
    #         - driver: nvidia
    #           count: 1
    #           capabilities: [gpu]

  # =============================================================================
  # Text-to-Speech Service (Piper)
  # =============================================================================
  tts:
    build: ./services/tts
    container_name: voicebot-tts
    environment:
      - PIPER_VOICE=${PIPER_VOICE:-en_US-lessac-medium}
    ports:
      - "8003:8003"
    volumes:
      - tts_models:/models
    restart: unless-stopped

  # =============================================================================
  # RAG Service (Vector Search)
  # =============================================================================
  rag:
    build: ./services/rag
    container_name: voicebot-rag
    environment:
      - EMBED_MODEL=${EMBED_MODEL:-intfloat/e5-small-v2}
      - VECTOR_DB=${VECTOR_DB:-faiss}
      - PG_DSN=${PG_DSN}
    ports:
      - "8004:8004"
    volumes:
      - rag_data:/data
    restart: unless-stopped
    depends_on:
      - postgres

  # =============================================================================
  # PostgreSQL (for pgvector if used)
  # =============================================================================
  postgres:
    image: pgvector/pgvector:pg16
    container_name: voicebot-postgres
    environment:
      - POSTGRES_USER=user
      - POSTGRES_PASSWORD=pass
      - POSTGRES_DB=rag
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
    restart: unless-stopped

  # =============================================================================
  # Nginx Reverse Proxy
  # =============================================================================
  nginx:
    build: ./services/nginx
    container_name: voicebot-nginx
    ports:
      - "80:80"
      - "443:443"
    depends_on:
      - app
    volumes:
      - ./services/nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./services/nginx/ssl:/etc/nginx/ssl:ro
    restart: unless-stopped

  # =============================================================================
  # Monitoring: Prometheus
  # =============================================================================
  prometheus:
    image: prom/prometheus:latest
    container_name: voicebot-prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./monitoring/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
    restart: unless-stopped

  # =============================================================================
  # Monitoring: Grafana
  # =============================================================================
  grafana:
    image: grafana/grafana:latest
    container_name: voicebot-grafana
    ports:
      - "3001:3000"
    environment:
      - GF_SECURITY_ADMIN_USER=${GRAFANA_ADMIN_USER:-admin}
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_ADMIN_PASSWORD:-admin}
    volumes:
      - ./monitoring/grafana/dashboards:/etc/grafana/provisioning/dashboards:ro
      - ./monitoring/grafana/datasources:/etc/grafana/provisioning/datasources:ro
      - grafana_data:/var/lib/grafana
    depends_on:
      - prometheus
    restart: unless-stopped

# =============================================================================
# Volumes for persistent data
# =============================================================================
volumes:
  llm_models:
    driver: local
  stt_models:
    driver: local
  tts_models:
    driver: local
  rag_data:
    driver: local
  postgres_data:
    driver: local
  prometheus_data:
    driver: local
  grafana_data:
    driver: local

