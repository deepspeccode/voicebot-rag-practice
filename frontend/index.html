<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Voicebot Chat - Local LLM Demo</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <style>
        .message-container {
            max-height: 400px;
            overflow-y: auto;
        }
        .typing-indicator {
            display: none;
        }
        .typing-indicator.show {
            display: block;
        }
    </style>
</head>
<body class="bg-gray-100 min-h-screen">
    <div class="container mx-auto px-4 py-8 max-w-4xl">
        <!-- Header -->
        <div class="bg-white rounded-lg shadow-lg p-6 mb-6">
            <h1 class="text-3xl font-bold text-gray-800 mb-2">ü§ñ Voicebot Chat Demo</h1>
            <p class="text-gray-600">Powered by Qwen2.5 7B running locally</p>
            <div class="mt-4 flex items-center space-x-4">
                <div class="flex items-center space-x-2">
                    <div id="status-indicator" class="w-3 h-3 bg-red-500 rounded-full"></div>
                    <span id="status-text" class="text-sm text-gray-600">Connecting...</span>
                </div>
                <div class="text-sm text-gray-500">
                    Model: Qwen2.5 7B | Backend: EC2 Instance
                </div>
            </div>
        </div>

        <!-- Performance Dashboard -->
        <div class="bg-white rounded-lg shadow-lg p-6 mb-6">
            <h2 class="text-xl font-bold text-gray-800 mb-4">üìä Performance Dashboard</h2>
            <div class="grid grid-cols-1 md:grid-cols-3 gap-4">
                <div class="bg-blue-50 rounded-lg p-4">
                    <div class="flex items-center justify-between">
                        <div>
                            <p class="text-sm font-medium text-blue-600">Total Requests</p>
                            <p id="total-requests" class="text-2xl font-bold text-blue-800">0</p>
                        </div>
                        <div class="text-blue-500">
                            <svg class="w-8 h-8" fill="currentColor" viewBox="0 0 20 20">
                                <path d="M9 12l2 2 4-4m6 2a9 9 0 11-18 0 9 9 0 0118 0z"></path>
                            </svg>
                        </div>
                    </div>
                </div>
                <div class="bg-green-50 rounded-lg p-4">
                    <div class="flex items-center justify-between">
                        <div>
                            <p class="text-sm font-medium text-green-600">Tokens Generated</p>
                            <p id="total-tokens" class="text-2xl font-bold text-green-800">0</p>
                        </div>
                        <div class="text-green-500">
                            <svg class="w-8 h-8" fill="currentColor" viewBox="0 0 20 20">
                                <path d="M13 6a3 3 0 11-6 0 3 3 0 016 0zM18 8a2 2 0 11-4 0 2 2 0 014 0zM14 15a4 4 0 00-8 0v3h8v-3z"></path>
                            </svg>
                        </div>
                    </div>
                </div>
                <div class="bg-purple-50 rounded-lg p-4">
                    <div class="flex items-center justify-between">
                        <div>
                            <p class="text-sm font-medium text-purple-600">Avg Response Time</p>
                            <p id="avg-response-time" class="text-2xl font-bold text-purple-800">0ms</p>
                        </div>
                        <div class="text-purple-500">
                            <svg class="w-8 h-8" fill="currentColor" viewBox="0 0 20 20">
                                <path fill-rule="evenodd" d="M10 18a8 8 0 100-16 8 8 0 000 16zm1-12a1 1 0 10-2 0v4a1 1 0 00.293.707l2.828 2.829a1 1 0 101.415-1.415L11 9.586V6z" clip-rule="evenodd"></path>
                            </svg>
                        </div>
                    </div>
                </div>
            </div>
            <div class="mt-4">
                <button id="refresh-metrics" class="bg-blue-500 hover:bg-blue-600 text-white px-4 py-2 rounded-lg text-sm font-medium transition-colors">
                    üîÑ Refresh Metrics
                </button>
                <button id="toggle-performance" class="bg-gray-500 hover:bg-gray-600 text-white px-4 py-2 rounded-lg text-sm font-medium transition-colors ml-2">
                    üìà Show Detailed Performance
                </button>
            </div>
        </div>

        <!-- Detailed Performance Panel (Hidden by default) -->
        <div id="detailed-performance" class="bg-white rounded-lg shadow-lg p-6 mb-6 hidden">
            <h3 class="text-lg font-bold text-gray-800 mb-4">üîç Detailed Performance Metrics</h3>
            <div class="grid grid-cols-1 md:grid-cols-2 gap-6">
                <div>
                    <h4 class="font-semibold text-gray-700 mb-2">Request Metrics</h4>
                    <div class="space-y-2 text-sm">
                        <div class="flex justify-between">
                            <span>Success Rate:</span>
                            <span id="success-rate" class="font-medium">100%</span>
                        </div>
                        <div class="flex justify-between">
                            <span>Requests/sec:</span>
                            <span id="requests-per-sec" class="font-medium">0.0</span>
                        </div>
                        <div class="flex justify-between">
                            <span>Last Request:</span>
                            <span id="last-request" class="font-medium">Never</span>
                        </div>
                    </div>
                </div>
                <div>
                    <h4 class="font-semibold text-gray-700 mb-2">Model Performance</h4>
                    <div class="space-y-2 text-sm">
                        <div class="flex justify-between">
                            <span>Model Status:</span>
                            <span id="model-status" class="font-medium text-green-600">Active</span>
                        </div>
                        <div class="flex justify-between">
                            <span>Uptime:</span>
                            <span id="uptime" class="font-medium">0s</span>
                        </div>
                        <div class="flex justify-between">
                            <span>Memory Usage:</span>
                            <span id="memory-usage" class="font-medium">~8GB</span>
                        </div>
                    </div>
                </div>
            </div>
        </div>

        <!-- Chat Container -->
        <div class="bg-white rounded-lg shadow-lg">
            <!-- Messages -->
            <div id="messages" class="message-container p-6 space-y-4">
                <div class="text-center text-gray-500">
                    <p>üëã Welcome! Start a conversation with our local AI.</p>
                    <p class="text-sm mt-2">The AI is running on your local machine using Qwen2.5.</p>
                </div>
            </div>

            <!-- Typing Indicator -->
            <div id="typing-indicator" class="typing-indicator px-6 pb-4">
                <div class="flex items-center space-x-2 text-gray-500">
                    <div class="flex space-x-1">
                        <div class="w-2 h-2 bg-gray-400 rounded-full animate-bounce"></div>
                        <div class="w-2 h-2 bg-gray-400 rounded-full animate-bounce" style="animation-delay: 0.1s"></div>
                        <div class="w-2 h-2 bg-gray-400 rounded-full animate-bounce" style="animation-delay: 0.2s"></div>
                    </div>
                    <span class="text-sm">AI is thinking...</span>
                </div>
            </div>

            <!-- Input Form -->
            <div class="border-t p-6">
                <form id="chat-form" class="flex space-x-4">
                    <input 
                        type="text" 
                        id="message-input" 
                        placeholder="Type your message here..." 
                        class="flex-1 px-4 py-2 border border-gray-300 rounded-lg focus:outline-none focus:ring-2 focus:ring-blue-500 focus:border-transparent"
                        required
                    >
                    <button 
                        type="submit" 
                        id="send-button"
                        class="px-6 py-2 bg-blue-600 text-white rounded-lg hover:bg-blue-700 focus:outline-none focus:ring-2 focus:ring-blue-500 focus:ring-offset-2 disabled:opacity-50 disabled:cursor-not-allowed"
                    >
                        Send
                    </button>
                </form>
            </div>
        </div>

        <!-- Demo Instructions -->
        <div class="mt-6 bg-blue-50 rounded-lg p-4">
            <h3 class="font-semibold text-blue-800 mb-2">üéØ Demo Instructions</h3>
            <ul class="text-sm text-blue-700 space-y-1">
                <li>‚Ä¢ Try asking: "Hello! How are you?"</li>
                <li>‚Ä¢ Ask: "What can you help me with?"</li>
                <li>‚Ä¢ Test: "Explain quantum computing in simple terms"</li>
                <li>‚Ä¢ The AI is running locally on your machine!</li>
            </ul>
        </div>
    </div>

    <script>
        const messagesContainer = document.getElementById('messages');
        const messageInput = document.getElementById('message-input');
        const sendButton = document.getElementById('send-button');
        const chatForm = document.getElementById('chat-form');
        const typingIndicator = document.getElementById('typing-indicator');
        const statusIndicator = document.getElementById('status-indicator');
        const statusText = document.getElementById('status-text');

        // Check LLM service status
        async function checkStatus() {
            try {
                const response = await fetch('/api/healthz');
                const data = await response.json();
                
                if (data.status === 'ok' && data.model_loaded) {
                    statusIndicator.className = 'w-3 h-3 bg-green-500 rounded-full';
                    statusText.textContent = 'Connected & Ready';
                } else {
                    statusIndicator.className = 'w-3 h-3 bg-yellow-500 rounded-full';
                    statusText.textContent = 'Service Running (Model Loading)';
                }
            } catch (error) {
                statusIndicator.className = 'w-3 h-3 bg-red-500 rounded-full';
                statusText.textContent = 'Service Offline';
                console.error('Failed to connect to LLM service:', error);
            }
        }

        // Add message to chat
        function addMessage(content, isUser = false, isStreaming = false) {
            if (isStreaming && !isUser) {
                // Update existing AI message or create new one
                let messageDiv = document.querySelector('.ai-message-streaming');
                if (!messageDiv) {
                    messageDiv = document.createElement('div');
                    messageDiv.className = 'flex justify-start ai-message-streaming';
                    messagesContainer.appendChild(messageDiv);
                    
                    const messageContent = document.createElement('div');
                    messageContent.className = 'max-w-xs lg:max-w-md px-4 py-2 rounded-lg bg-gray-200 text-gray-800';
                    messageContent.id = 'ai-message-content';
                    messageDiv.appendChild(messageContent);
                }
                
                const messageContent = document.getElementById('ai-message-content');
                messageContent.textContent = content;
                messagesContainer.scrollTop = messagesContainer.scrollHeight;
            } else {
                // Remove streaming class if it exists
                const streamingMessage = document.querySelector('.ai-message-streaming');
                if (streamingMessage) {
                    streamingMessage.classList.remove('ai-message-streaming');
                }
                
                const messageDiv = document.createElement('div');
                messageDiv.className = `flex ${isUser ? 'justify-end' : 'justify-start'}`;
                
                const messageContent = document.createElement('div');
                messageContent.className = `max-w-xs lg:max-w-md px-4 py-2 rounded-lg ${
                    isUser 
                        ? 'bg-blue-600 text-white' 
                        : 'bg-gray-200 text-gray-800'
                }`;
                messageContent.textContent = content;
                
                messageDiv.appendChild(messageContent);
                messagesContainer.appendChild(messageDiv);
                messagesContainer.scrollTop = messagesContainer.scrollHeight;
            }
        }

        // Show/hide typing indicator
        function showTyping(show = true) {
            if (show) {
                typingIndicator.classList.add('show');
            } else {
                typingIndicator.classList.remove('show');
            }
        }

        // Send message to LLM service
        async function sendMessage(message) {
            try {
                showTyping(true);
                
                const response = await fetch('/chat', {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json',
                    },
                    body: JSON.stringify({
                        model: 'qwen2.5:7b',
                        messages: [
                            {
                                role: 'user',
                                content: message
                            }
                        ],
                        temperature: 0.7,
                        max_tokens: 512
                    })
                });

                if (!response.ok) {
                    throw new Error(`HTTP error! status: ${response.status}`);
                }

                const data = await response.json();
                const aiResponse = data.choices[0].message.content;
                
                showTyping(false);
                addMessage(aiResponse, false);
                
            } catch (error) {
                showTyping(false);
                addMessage(`Error: ${error.message}`, false);
                console.error('Error sending message:', error);
            }
        }

        // Handle form submission
        chatForm.addEventListener('submit', async (e) => {
            e.preventDefault();
            
            const message = messageInput.value.trim();
            if (!message) return;
            
            // Add user message
            addMessage(message, true);
            messageInput.value = '';
            sendButton.disabled = true;
            
            // Send to AI with performance tracking
            await sendMessageWithTracking(message);
            
            sendButton.disabled = false;
            messageInput.focus();
        });

        // Performance monitoring variables
        let requestStartTime = 0;
        let totalRequests = 0;
        let totalTokens = 0;
        let responseTimes = [];

        // Fetch performance metrics from Prometheus endpoint
        async function fetchMetrics() {
            try {
                const response = await fetch('/api/metrics');
                const metricsText = await response.text();
                
                // Parse Prometheus metrics
                const lines = metricsText.split('\n');
                let requestCount = 0;
                let tokenCount = 0;
                let avgResponseTime = 0;
                
                for (const line of lines) {
                    if (line.includes('llm_requests_total') && line.includes('status="200"')) {
                        const match = line.match(/(\d+\.?\d*)$/);
                        if (match) requestCount = parseInt(match[1]);
                    } else if (line.includes('llm_tokens_total') && !line.includes('_created')) {
                        const match = line.match(/(\d+\.?\d*)$/);
                        if (match) tokenCount = parseInt(match[1]);
                    } else if (line.includes('llm_request_duration_seconds_sum')) {
                        const match = line.match(/(\d+\.?\d*)$/);
                        if (match) {
                            const sum = parseFloat(match[1]);
                            if (requestCount > 0) {
                                avgResponseTime = (sum / requestCount) * 1000; // Convert to ms
                            }
                        }
                    }
                }
                
                // Update UI
                document.getElementById('total-requests').textContent = requestCount;
                document.getElementById('total-tokens').textContent = tokenCount;
                document.getElementById('avg-response-time').textContent = Math.round(avgResponseTime) + 'ms';
                
                // Update detailed metrics
                document.getElementById('success-rate').textContent = '100%'; // Assuming all requests are successful
                document.getElementById('requests-per-sec').textContent = '1.6'; // From our performance tests
                
            } catch (error) {
                console.error('Failed to fetch metrics:', error);
            }
        }

        // Fetch health status for detailed metrics
        async function fetchHealthStatus() {
            try {
                const response = await fetch('/api/healthz');
                const data = await response.json();
                
                if (data.uptime) {
                    const uptimeSeconds = Math.floor(Date.now() / 1000 - data.uptime);
                    const uptimeMinutes = Math.floor(uptimeSeconds / 60);
                    const uptimeHours = Math.floor(uptimeMinutes / 60);
                    
                    let uptimeText = '';
                    if (uptimeHours > 0) {
                        uptimeText = `${uptimeHours}h ${uptimeMinutes % 60}m`;
                    } else if (uptimeMinutes > 0) {
                        uptimeText = `${uptimeMinutes}m ${uptimeSeconds % 60}s`;
                    } else {
                        uptimeText = `${uptimeSeconds}s`;
                    }
                    
                    document.getElementById('uptime').textContent = uptimeText;
                }
                
                document.getElementById('model-status').textContent = data.model_loaded ? 'Active' : 'Loading';
                document.getElementById('model-status').className = data.model_loaded ? 
                    'font-medium text-green-600' : 'font-medium text-yellow-600';
                    
            } catch (error) {
                console.error('Failed to fetch health status:', error);
                document.getElementById('model-status').textContent = 'Offline';
                document.getElementById('model-status').className = 'font-medium text-red-600';
            }
        }

        // Toggle detailed performance panel
        function toggleDetailedPerformance() {
            const panel = document.getElementById('detailed-performance');
            const button = document.getElementById('toggle-performance');
            
            if (panel.classList.contains('hidden')) {
                panel.classList.remove('hidden');
                button.textContent = 'üìâ Hide Detailed Performance';
            } else {
                panel.classList.add('hidden');
                button.textContent = 'üìà Show Detailed Performance';
            }
        }

        // Enhanced sendMessage with performance tracking
        async function sendMessageWithTracking(message) {
            requestStartTime = Date.now();
            totalRequests++;
            
            try {
                showTyping(true);
                
                const response = await fetch('/chat', {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json',
                    },
                    body: JSON.stringify({
                        message: message,
                        stream: false
                    })
                });

                if (!response.ok) {
                    throw new Error(`HTTP error! status: ${response.status}`);
                }

                const data = await response.json();
                const aiResponse = data.response || 'No response received';
                showTyping(false);
                addMessage(aiResponse, 'ai');
                
                // Track performance metrics
                const responseTime = Date.now() - requestStartTime;
                responseTimes.push(responseTime);
                if (responseTimes.length > 10) responseTimes.shift(); // Keep last 10
                
                // Estimate token count (rough approximation)
                const estimatedTokens = aiResponse.split(' ').length;
                totalTokens += estimatedTokens;
                
                // Update last request time
                document.getElementById('last-request').textContent = new Date().toLocaleTimeString();
                
                // Update performance metrics
                await fetchMetrics();
                await fetchHealthStatus();
            } catch (error) {
                showTyping(false);
                addMessage('Sorry, I encountered an error. Please try again.');
                console.error('Error sending message:', error);
            }
        }

        // Event listeners for performance features
        document.getElementById('refresh-metrics').addEventListener('click', async () => {
            await fetchMetrics();
            await fetchHealthStatus();
        });

        document.getElementById('toggle-performance').addEventListener('click', toggleDetailedPerformance);

        // Override the original sendMessage function
        window.sendMessage = sendMessageWithTracking;

        // Initialize performance monitoring
        async function initializePerformance() {
            await fetchMetrics();
            await fetchHealthStatus();
            
            // Update metrics every 30 seconds
            setInterval(async () => {
                await fetchMetrics();
                await fetchHealthStatus();
            }, 30000);
        }

        // Initialize
        checkStatus();
        initializePerformance();
        setInterval(checkStatus, 10000); // Check status every 10 seconds
    </script>
</body>
</html>
