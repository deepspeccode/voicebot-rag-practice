{
  "model_name": "phi-3-mini",
  "model_file": "Phi-3-mini-4k-instruct-Q4_K_M.gguf",
  "model_path": "/models/Phi-3-mini-4k-instruct-Q4_K_M.gguf",
  "quantization": "Q4_K_M",
  "context_size": 2048,
  "max_tokens": 512,
  "temperature": 0.7,
  "top_p": 0.9,
  "threads": 4,
  "batch_size": 512,
  "n_gpu_layers": 0,
  "description": "Phi-3 Mini 4K Instruct model with Q4_K_M quantization - extremely fast for testing"
}
